{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **張量（Tensor）**\n",
    "是數學和計算科學中的一個基本概念，用於表示**多維數據結構**。在機器學習和深度學習中，張量是數據的基本表示形式，類似於標量、向量和矩陣，但可以擁有更多的維度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. **處理更高維度的數據**\n",
    "**圖像數據：** 圖像數據通常是三維（高度、寬度、通道），如果再考慮批量處理（batch processing），就需要四維張量。\n",
    "例如，一批 32 個彩色圖像，每個圖像大小為 64x64 像素，這可以表示為形狀為 (32,64,64,3) 的四維張量。\n",
    "\n",
    "**視頻數據：** 視頻數據通常是四維（幀數、高度、寬度、通道），再加上批次維度就是五維張量。\n",
    "\n",
    "**自然語言處理：** 文本數據在表示為嵌入（embedding）時，通常需要三維張量（批量大小、序列長度、嵌入維度）。\n",
    "\n",
    "\n",
    "#### **2. 更靈活的數據操作**\n",
    "**廣播機制：** 張量操作支持廣播機制，使得不同形狀的張量之間可以進行運算，而不需要明確地對齊它們的形狀。\n",
    "\n",
    "**高效計算：** 深度學習框架（如 TensorFlow 和 PyTorch）對張量操作進行了高度優化，利用 GPU 加速，提供了高效的數值計算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(87)\n",
    "y = torch.tensor([[1, 2], [3, 4]])\n",
    "z = torch.tensor([[[1,2,3],[1,2,3]]])\n",
    "y.ndim\n",
    "z.shape#第一個[]中有一個值 第二個[]有兩個值 第三個[]有三個值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0036, 0.8931, 0.4548, 0.9815],\n",
       "         [0.5443, 0.1487, 0.0450, 0.5285],\n",
       "         [0.6307, 0.6676, 0.3723, 0.8175]],\n",
       "\n",
       "        [[0.1480, 0.5822, 0.1032, 0.3165],\n",
       "         [0.9750, 0.1861, 0.9619, 0.9053],\n",
       "         [0.7163, 0.3249, 0.4789, 0.0177]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(87)#正常來說每次產生的值為0~1之隨機值 可用此方式固定\n",
    "x = torch.rand(2, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(3 ,4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 11, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cpu'), False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0.1, 0.2, 0.3],\n",
    "                 dtype=None,#資料型態 預設為自動感應\n",
    "                 device=None,#運行的設備 預設為cpu\n",
    "                 requires_grad=False)#是否追蹤梯度\n",
    "x.dtype, x.device, x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1000, 1.2000, 1.3000],\n",
       "        [1.4000, 1.5000, 1.6000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#取值和數值改變\n",
    "x = torch.tensor([[0.1, 0.2, 0.3],\n",
    "                 [0.4, 0.5, 0.6]])\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1000, 1.2000, 1.3000],\n",
       "        [1.4000, 1.5000, 1.6000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[0.1, 0.2, 0.3],\n",
    "                 [0.4, 0.5, 0.6]])\n",
    "x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, 12, 15],\n",
       "        [19, 26, 33],\n",
       "        [29, 40, 51]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩陣相乘\n",
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])\n",
    "\n",
    "y = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "torch.matmul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 5],\n",
       "        [2, 4, 6]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#轉置\n",
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])\n",
    "\n",
    "x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 10)\n",
    "x.reshape(2, 5)#注意改變的值要和原本一樣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), tensor([1, 2, 3], dtype=torch.int32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩陣轉張量\n",
    "import numpy as np\n",
    "\n",
    "array = np.array([1, 2, 3])\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), array([1, 2, 3], dtype=int64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#張量轉矩陣\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "array = tensor.numpy()\n",
    "tensor, array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
